{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2kQ_-6NSIAn2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() # definindo a convesão de imagem para tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # Carrega a parte de treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # Cria um fuffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False,transform=transform) # Carrega a parte de validação do dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # Cria um buffer para pegar os dados por partes\n"
      ],
      "metadata": {
        "id": "TD_CktciMDip"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainloader)\n",
        "imagens, etiquetas = next(dataiter)\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "TAsu2GfKWhXB",
        "outputId": "ae082209-145f-459a-e661-0432b6df4533"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ecdbca7d7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) # Para verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) # Para verificar as dimensões do tensor de cada etiqueta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK4rmqsyWhcr",
        "outputId": "edf0a79b-8d62-4a5d-e0fb-b7be4a2688e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a rede neural\n",
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.fc2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligal a 64\n",
        "        self.fc3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligal a 10\n",
        "        # para a camada de saída não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x)) # função de ativação da camada de entrada para a camada interna 1\n",
        "        x = F.relu(self.linear2(x)) # função de ativação da camada de interna 1 para a camada interna 2\n",
        "        x = F.relu(self.linear3(x)) # função de ativação da camada de interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "\n",
        "        return  F.log_softmax(x, dim=1) # dados utilizados para calcular a perda\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0t25Ts5CWhhE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.05) # define a política de atualização dos pesos e da bias\n",
        "  inicio = time() # timer para sabermos o tempo que lebou o treino\n",
        "\n",
        "  criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
        "  EPOCHS = 10 # numero de epochs que o algoritmo rodará / um bom treinamento é no minimo 100 epochs\n",
        "  modelo.train() # ativando o mode de treinamento do modelo\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0 # inicializaão de perda acumulada da epoch em questão\n",
        "\n",
        "    for imagens, etiquetas in trainloader:\n",
        "\n",
        "      imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para \"vetores\" de 28*28 casas para ficarem compatíveus com a\n",
        "      otimizador.zero_grad() # zerando os gradientes por conta do ciclo anterior\n",
        "\n",
        "      output = modelo(imagens.to(device)) # zerando os gradientets por conta do cuclo anterior\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
        "\n",
        "      perda_instantanea.backward() # back propagation a partir da perda\n",
        "\n",
        "      otimizador.step() # atualizando os pesos e bias\n",
        "\n",
        "\n",
        "      perda_acumudala += perda_instantanea.item() # atualizando a perda acumulada\n",
        "\n",
        "    else:\n",
        "      print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "\n",
        "  print(\"\\nTempo de treino (em minutos) =\",(time()-inicio)/60)\n",
        ""
      ],
      "metadata": {
        "id": "D2wuJjQaXUKV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "      #desativar o autograd para acelevar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
        "\n",
        "\n",
        "      ps = torch.exp(logps) # converte output para escala normal (lembrando que é um tensor)\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      etiqueta_pred = probab.index(max(probab)) # converte tensor em um número, no caso, o nímero que o modelo previu como correto\n",
        "      etiqueta_certa = etiquetas.numpy([i])\n",
        "      if (etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
        "        conta_corretas +=1\n",
        "      conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrevisão do modelo = {}\".format(conta_corretas*100/conta_todas))"
      ],
      "metadata": {
        "id": "-ZVh_KjicyBR"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo() # inicializa o modelo\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # modelo rodará no GPU se possível\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXYzvVjwgO2p",
        "outputId": "c1ece941-592a-451c-dd71-39fb59554e8a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}